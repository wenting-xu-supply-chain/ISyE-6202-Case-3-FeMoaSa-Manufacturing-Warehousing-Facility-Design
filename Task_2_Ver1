import pandas as pd
import numpy as np
from scipy.stats import norm
import os
import io

# ============================================================
# Georgia Tech ISyE 6202 & 6335 - Casework 3
# Task 2: Finished Goods Storage Capacity Plan (FINAL)
# ============================================================

# --- Configuration ---
# 1. Define Input/Output Folders and Files
EXCEL_FILE_PATH = "iSYE+6202+%26+6335+2025+Casework+3+FaMoaSa++Facility+Design+-+Tables+and+Basic+Layouts.xlsx"
OUTPUT_DIR = "Task2_Outcome"
os.makedirs(OUTPUT_DIR, exist_ok=True)
print(f"üìÅ Output directory set to: {OUTPUT_DIR}")

# 2. Define Sheet Names (Confirmed from screenshots)
DEMAND_SHEET = "+1 Year Product Demand"
BOM_SHEET = "+1 Year Parts per Product"
SPECS_SHEET = "Parts Specs" # This sheet is corrupted in Excel, will be manually loaded

# 3. Define Header Rows (Confirmed from user's code)
ANNUAL_DEMAND_HEADER = 16 # Row 17 (This worked for your Task 1)
BOM_HEADER = 9            # Row 10 (This worked for your Task 1)
# SPECS_HEADER is not needed as we load it manually

# 4. Define Constants from PDF and Assumptions
SERVICE_LEVEL = 0.995 # 99.5% OTIF target
Z_SCORE = norm.ppf(SERVICE_LEVEL) # Approx 2.576
WEEKS_PER_YEAR = 52.0

# --- ASSUMPTIONS ---
L_WEEKS = 1.0 # 1-week replenishment lead time
FACTORY_BUFFER_WEEKS = 2.0 # 2-week buffer
SPACE_UTIL_FACTOR = 0.45 # 45% utilization for aisles, etc.
CLIENT_WH_HEIGHT_FT = 20.0 # Given in PDF
FACTORY_WH_HEIGHT_FT = 20.0 # Assumed same as client
CLIENT_WH_COST_PER_SQFT = 200.0 # Given in PDF
# 5. Define Output Filenames
OUTPUT_PLAN_FILE = os.path.join(OUTPUT_DIR, "task2_storage_plan_by_part.csv")
OUTPUT_SUMMARY_FILE = os.path.join(OUTPUT_DIR, "task2_physical_storage_summary.csv")
OUTPUT_README_FILE = os.path.join(OUTPUT_DIR, "README_Task2_Methodology.txt")


def get_manual_cv_data():
    """
    Manually transcribed data from PDF / screenshot '...21.58.55.png'
    This bypasses the pandas read error for the second table.
    """
    print("Loading manually transcribed data for 'Weekly CV'...")
    # Data from table "Expected Coefficient of Variation of Weekly Year +1 Demand"
    cv_data = {
        'A1': 0.15, # 15%
        'A2': 0.20, # 20%
        'A3': 0.20, # 20%
        'B1': 0.12, # 12%
        'B2': 0.18  # 18%
    }
    return pd.Series(cv_data)

def get_manual_specs_data():
    """
    Manually transcribed data from PDF Page 4 / screenshot '...21.59.17.png'
    This bypasses the corrupted 'Parts Specs' sheet in the user's Excel file.
    """
    print("Loading manually transcribed data for 'Parts Specs (Dimensions)'...")
    specs_data = {
        'Part': ['P1', 'P2', 'P3', 'P4', 'P5', 'P6', 'P7', 'P8', 'P9', 'P10',
                 'P11', 'P12', 'P13', 'P14', 'P15', 'P16', 'P17', 'P18', 'P19', 'P20'],
        'X': [2, 8, 6, 12, 8, 2, 2, 4, 2, 4, 4, 6, 2, 2, 4, 4, 12, 12, 12, 12],
        'Y': [6, 8, 6, 6, 4, 8, 2, 4, 4, 4, 6, 6, 2, 4, 6, 4, 2, 2, 2, 2],
        'Z': [6, 4, 6, 4, 6, 6, 12, 4, 12, 4, 4, 4, 12, 6, 4, 4, 2, 2, 2, 2]
    }
    df_specs = pd.DataFrame(specs_data).set_index('Part')
    return df_specs


def load_task2_data(excel_path):
    """Loads all necessary data for Task 2 calculations."""
    print("Reading data from Excel file...")
    
    # 1. Read Annual Demand (header=16, from user's successful code)
    df_annual_demand_raw = pd.read_excel(excel_path, sheet_name=DEMAND_SHEET, header=ANNUAL_DEMAND_HEADER)
    demand_df = df_annual_demand_raw[['Year', 'A1', 'A2', 'A3', 'B1', 'B2', 'Total']].dropna()
    demand_df_clean = demand_df[demand_df['Year'].astype(str).str.startswith('+')].reset_index(drop=True)
    s_annual_demand = demand_df_clean.iloc[0][['A1','A2','A3','B1','B2']].astype(float)
    s_annual_demand.index = ['A1', 'A2', 'A3', 'B1', 'B2']
    print(f"Loaded sheet: '{DEMAND_SHEET}' (Annual Avg Demand @ header 16)")
    
    # 2. Calculate Weekly Demand (per PDF)
    s_weekly_demand = s_annual_demand / WEEKS_PER_YEAR
    print("Calculated weekly average demand (Annual / 52).")
    
    # 3. Load Weekly CV (Manually to bypass read error)
    s_weekly_cv = get_manual_cv_data()

    # 4. Load Bill of Materials (BOM) (header=9, from user's successful code)
    parts_df_raw = pd.read_excel(excel_path, sheet_name=BOM_SHEET, header=BOM_HEADER)
    # Clean column names (from user's code)
    parts_df = parts_df_raw.rename(columns={
        'Parts per Assembled Product Unit Demanded in Year +1 ': 'A1',
        'Unnamed: 3': 'A2',
        'Unnamed: 4': 'A3',
        'Unnamed: 5': 'B1',
        'Unnamed: 6': 'B2'
    })
    parts_df = parts_df[['Part', 'A1', 'A2', 'A3', 'B1', 'B2']].dropna(subset=['Part'])
    df_bom = parts_df.set_index('Part')
    
    # Apply robust conversion (pd.to_numeric) to fix NaN/integer errors
    df_bom = df_bom.apply(pd.to_numeric, errors='coerce').fillna(0).astype(int)
    print(f"Loaded sheet: '{BOM_SHEET}' (@ header 9)")
    
    # 5. Load Parts Specs (Manually to bypass corrupted Excel sheet)
    df_specs = get_manual_specs_data()
    
    print("\nAll data successfully loaded.\n")
    return s_weekly_demand, s_weekly_cv, df_bom, df_specs

def calculate_storage_plan(s_weekly_demand, s_weekly_cv, df_bom):
    """Calculates the required inventory (SS, CS) at each location for each part."""
    print("Calculating safety and cycle stocks...")
    
    # --- Step 1: Calculate Weekly Demand Stats for Products ---
    s_weekly_stddev = s_weekly_demand * s_weekly_cv
    s_weekly_var = s_weekly_stddev**2
    
    # Split by client
    products_A = ['A1', 'A2', 'A3']
    products_B = ['B1', 'B2']
    
    # --- Step 2: Calculate Weekly Demand Stats for Parts (by Client) ---
    df_bom_A = df_bom[products_A]
    df_bom_B = df_bom[products_B]
    
    s_avg_parts_A = df_bom_A.dot(s_weekly_demand[products_A])
    s_avg_parts_B = df_bom_B.dot(s_weekly_demand[products_B])
    s_avg_parts_total = s_avg_parts_A + s_avg_parts_B
    
    s_var_parts_A = (df_bom_A**2).dot(s_weekly_var[products_A])
    s_var_parts_B = (df_bom_B**2).dot(s_weekly_var[products_B])
    
    s_stddev_parts_A = np.sqrt(s_var_parts_A)
    s_stddev_parts_B = np.sqrt(s_var_parts_B)
    
    # --- Step 3: Calculate Safety Stock (SS) for Client Warehouses ---
    ss_A = Z_SCORE * np.sqrt(L_WEEKS) * s_stddev_parts_A
    ss_B = Z_SCORE * np.sqrt(L_WEEKS) * s_stddev_parts_B
    
    # --- Step 4: Calculate Cycle Stock (CS) for Client Warehouses ---
    cs_A = (s_avg_parts_A * L_WEEKS) / 2.0
    cs_B = (s_avg_parts_B * L_WEEKS) / 2.0
    
    # --- Step 5: Calculate Total Stock for Client Warehouses ---
    s_total_stock_A = ss_A + cs_A
    s_total_stock_B = ss_B + cs_B
    
    # --- Step 6: Calculate Stock for Factory Outbound ---
    s_factory_stock = s_avg_parts_total * FACTORY_BUFFER_WEEKS
    
    # --- Step 7: Combine into Final Plan ---
    df_plan = pd.DataFrame({
        "Avg_Weekly_Demand_A": s_avg_parts_A,
        "Safety_Stock_A (SS)": ss_A,
        "Cycle_Stock_A (CS)": cs_A,
        "Total_Warehouse_A_Stock": s_total_stock_A,
        "Avg_Weekly_Demand_B": s_avg_parts_B,
        "Safety_Stock_B (SS)": ss_B,
        "Cycle_Stock_B (CS)": cs_B,
        "Total_Warehouse_B_Stock": s_total_stock_B,
        "Factory_Outbound_Stock": s_factory_stock,
        "Total_System_Inventory": s_total_stock_A + s_total_stock_B + s_factory_stock
    })
    
    stock_cols = df_plan.columns.drop(df_plan.filter(like='Avg_').columns)
    df_plan[stock_cols] = df_plan[stock_cols].apply(np.ceil).astype(int)
    
    print("Stock plan calculation complete.\n")
    return df_plan

def calculate_physical_size(df_plan, df_specs):
    """Calculates the physical storage volume and square footage."""
    print("Calculating physical storage requirements...")
    
    df_specs['Volume_CF'] = (df_specs['X'] * df_specs['Y'] * df_specs['Z']) / 1728.0
    
    df_plan_with_volume = df_plan.merge(df_specs[['Volume_CF']], left_index=True, right_index=True)
        vol_A = (df_plan_with_volume['Total_Warehouse_A_Stock'] * df_plan_with_volume['Volume_CF']).sum()
    vol_B = (df_plan_with_volume['Total_Warehouse_B_Stock'] * df_plan_with_volume['Volume_CF']).sum()
    vol_Factory = (df_plan_with_volume['Factory_Outbound_Stock'] * df_plan_with_volume['Volume_CF']).sum()
    
    sqft_A = (vol_A / SPACE_UTIL_FACTOR) / CLIENT_WH_HEIGHT_FT
    sqft_B = (vol_B / SPACE_UTIL_FACTOR) / CLIENT_WH_HEIGHT_FT
    sqft_Factory = (vol_Factory / SPACE_UTIL_FACTOR) / FACTORY_WH_HEIGHT_FT
    
    cost_A = sqft_A * CLIENT_WH_COST_PER_SQFT
    cost_B = sqft_B * CLIENT_WH_COST_PER_SQFT
    
    summary_data = {
        'Location': ['Warehouse A', 'Warehouse B', 'Factory Outbound'],
        'Purpose': ['Service Client A', 'Service Client B', 'Replenish Warehouses'],
        'Total_Storage_Volume_CF': [vol_A, vol_B, vol_Factory],
        'Required_Sq_Footage': [sqft_A, sqft_B, sqft_Factory],
        'Est_Building_Cost': [cost_A, cost_B, 'N/A (Part of Factory)']
    }
    df_summary = pd.DataFrame(summary_data)
    
    print("Physical size calculation complete.\n")
    return df_plan_with_volume, df_summary

def write_readme_file(output_file):
    """Writes a README file explaining the methodology for Task 2."""
    
    readme_content = f"""
    Task 2: Finished Storage Capacity Plan - Methodology
    ===================================================
    
    This folder contains the full storage plan for Task 2.
    
    Files Generated:
    ----------------
    1. {os.path.basename(OUTPUT_PLAN_FILE)}:
       A detailed table showing the calculated inventory (in units)
       for each part (P1-P20) at each of the three locations.
       
    2. {os.path.basename(OUTPUT_SUMMARY_FILE)}:
       A summary of the total physical storage volume (Cubic Feet)
       and required building footprint (Square Feet) for each location.
    
    3. {os.path.basename(OUTPUT_README_FILE)}:
       This file, explaining the strategic decisions and calculations.
    
    
    Strategic Justification:
    --------------------------
    The core requirement is to "robustly respect" the 99.5% OTIF service level.
    The replenishment windows are extremely tight:
    * Client A: Once per hour.
    * Client B: Once every four hours.
    
    The factory is located 90 miles (Client A) and 110 miles (Client B) away.
    It is *not physically possible* to load a truck and drive 90 miles in under 1 hour.
    Therefore, a decentralized storage strategy is **mandatory**.
    
    The proposed plan is:
    1.  **Warehouse A (Near Client A):** Holds all safety stock and cycle stock
        required to service Client A's hourly replenishments.
    2.  **Warehouse B (Near Client B):** Holds all safety stock and cycle stock
        required to service Client B's 4-hour replenishments.
    3.  **Factory Outbound Storage:** Holds a buffer stock to decouple production
        from warehouse replenishment, ensuring it can reliably ship to
        the warehouses.
        
    
    Calculation Methodology:
    --------------------------
    1.  **Lead Time (L):** We assume a 1-week (L=1.0) replenishment lead time
        from the factory to the two client warehouses. This is a reasonable
        assumption given the distance and need for robust planning.
        
    2.  **Weekly Demand Stats:**
        * Avg Weekly Demand was *calculated* (Annual Demand / 52).
        * Weekly CV was *manually transcribed* from the PDF/screenshots.
        * These were combined with the BOM to get part-level demand stats.
        
    3.  **Safety Stock (SS) at Warehouses:**
        * Calculated to cover demand uncertainty during the 1-week
          replenishment lead time at a 99.5% service level.
        * Formula: SS = Z * sqrt(L) * (Weekly_Part_StdDev)
        * Z-Score = {Z_SCORE:.3f} (for 99.5% service level)
        
    4.  **Cycle Stock (CS) at Warehouses:**
        * The average inventory held to cover demand between replenishments.
        * Formula: CS = (Avg_Weekly_Part_Demand * L) / 2
        
    5.  **Factory Stock:**
        * Assumed to hold a {FACTORY_BUFFER_WEEKS}-week buffer of *total* average
          weekly demand to ensure it can reliably replenish both warehouses.
          
    6.  **Physical Size:**
        * Part volumes (Cubic Feet) were *manually transcribed* from the PDF,
          as the 'Parts Specs' sheet in the Excel file was corrupted
          (it contained 'Process' data).
        * A {SPACE_UTIL_FACTOR*100}% space utilization factor was assumed for
          "standard racking" to account for aisles.
        * Required Square Footage = (Total Volume / {SPACE_UTIL_FACTOR}) / {CLIENT_WH_HEIGHT_FT} ft height.
        * Warehouse building cost was calculated at ${CLIENT_WH_COST_PER_SQFT}/sq ft.
    """
    
    with open(output_file, 'w', encoding='utf-8') as f:
        f.write(readme_content)
    print(f"Successfully saved README file to: '{OUTPUT_README_FILE}'")


def main():
    """Main function to execute Task 2."""
    try:
        # Step 1: Load all data from Excel
        s_weekly_demand, s_weekly_cv, df_bom, df_specs = load_task2_data(EXCEL_FILE_PATH)
        
        # Step 2: Calculate the inventory plan (SS, CS)
        df_plan = calculate_storage_plan(s_weekly_demand, s_weekly_cv, df_bom)
        
        # Step 3: Calculate physical volumes and square footage
        df_plan_with_volume, df_summary = calculate_physical_size(df_plan, df_specs)
        
        # Step 4: Save results to CSV files
        df_plan_with_volume.to_csv(OUTPUT_PLAN_FILE)
        print(f"Successfully saved part-by-part plan to: '{OUTPUT_PLAN_FILE}'")
        
        df_summary.to_csv(OUTPUT_SUMMARY_FILE, index=False)
        print(f"Successfully saved physical summary to: '{OUTPUT_SUMMARY_FILE}'")
        
        # Step 5: Write the methodology README
        write_readme_file(OUTPUT_README_FILE)
        
        print(f"\n--- Task 2 Complete. Folder '{OUTPUT_DIR}' successfully created with 3 files. ---")
        print("\n--- Physical Storage Summary ---")
        
        # --- *** FIX IS HERE *** ---
        # Create a dictionary of formatters that can handle strings
        formatters = {
            'Est_Building_Cost': lambda x: '${:,.2f}'.format(x) if isinstance(x, (int, float)) else x,
            'Total_Storage_Volume_CF': '{:,.2f} cf'.format,
            'Required_Sq_Footage': '{:,.2f} sq ft'.format
        }
        # Apply the smart formatters
        print(df_summary.to_string(formatters=formatters))
        # --- *** END OF FIX *** ---

    except FileNotFoundError as e:
        print(f"FATAL ERROR (File): {e}")
        print(f"Please ensure the file '{EXCEL_FILE_PATH}' is in the same directory.")
    except (ValueError, KeyError) as e:
        print(f"FATAL ERROR (Sheet/Data): {e}")
        print("\nThis error means a specific Sheet Name, Header Row, or Column Name is incorrect.")
        print("Please verify your Excel file matches the code's expectations (e.g., column names).")
    except Exception as e:
        print(f"An unexpected error occurred: {e}")

# --- Execute the main function ---
# This line *calls* the main function to run the script.
main()
